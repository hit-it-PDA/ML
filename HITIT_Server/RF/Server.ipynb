{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AKIA5ZUD4J2HM4V3SN52\n",
      "An error occurred: An error occurred (403) when calling the HeadObject operation: Forbidden\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import botocore\n",
    "import tarfile\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "kid = os.getenv('aws_access_key_id')\n",
    "akey = os.getenv('aws_secret_access_key')\n",
    "rname = os.getenv('region_name')\n",
    "bname = os.getenv('bucket_name')\n",
    "\n",
    "import numpy as np\n",
    "s3 = boto3.client('s3',\n",
    "            kid = aws_access_key_id,\n",
    "            akey = aws_secret_access_key,\n",
    "            rname = region_name\n",
    "        ) \n",
    "\n",
    "bucket_name = bname\n",
    "file_key = 'saved_model/model'  # 정확한 파일 키\n",
    "local_file_path = 'loaded_model'  # 로컬에 저장할 파일 경로\n",
    "\n",
    "# 파일 다운로드\n",
    "try:\n",
    "    s3.download_file(bucket_name, file_key, local_file_path)\n",
    "    print(f'File downloaded to {local_file_path}')\n",
    "except boto3.exceptions.S3UploadFailedError as e:\n",
    "    print(f'Error downloading file: {e}')\n",
    "except Exception as e:\n",
    "    print(f'An error occurred: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# 모델 불러오기\n",
    "model_output_path = 'loaded_model'\n",
    "loaded_model = joblib.load(model_output_path)\n",
    "\n",
    "print('Model loaded successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {3: '매우공격적', 2: '공격적', 1: '안정적', 0: '소극적'}\n",
    "map_func = np.vectorize(mapping.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['안정적' '안정적']\n"
     ]
    }
   ],
   "source": [
    "# 예측 수행\n",
    "single_prediction = loaded_model.predict([[42454, 40, 32, 29.33, 291],[42454, 40, 32, 29.33, 291]])\n",
    "print(map_func(single_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        data = request.json['data']\n",
    "        print(\"입력 데이터:\", data)\n",
    "        \n",
    "        # 모델 예측 (예시로서 model_layer 함수 사용)\n",
    "        predictions = loaded_model.predict(data)  # model_layer 함수가 TensorFlow 텐서를 반환한다고 가정\n",
    "        return_predict = map_func(predictions).tolist()\n",
    "        print(return_predict)\n",
    "        return jsonify({'predicted_class': return_predict })\n",
    "        \n",
    "\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from waitress import serve\n",
    "    serve(app, host=\"0.0.0.0\", port=8080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flask app is running with PID 14771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-17 10:47:03.726320: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-17 10:47:03.730176: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-17 10:47:03.782451: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-17 10:47:04.617727: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/ubuntu/code/DE_ML/HITIT_Server/myenv/lib/python3.12/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.4.2 when using version 1.4.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/ubuntu/code/DE_ML/HITIT_Server/myenv/lib/python3.12/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.4.2 when using version 1.4.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/code/DE_ML/HITIT_Server/RF/app.py\", line 35, in <module>\n",
      "    serve(app, host=\"0.0.0.0\", port=8080)\n",
      "  File \"/home/ubuntu/code/DE_ML/HITIT_Server/myenv/lib/python3.12/site-packages/waitress/__init__.py\", line 13, in serve\n",
      "    server = _server(app, **kw)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/code/DE_ML/HITIT_Server/myenv/lib/python3.12/site-packages/waitress/server.py\", line 78, in create_server\n",
      "    last_serv = TcpWSGIServer(\n",
      "                ^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/code/DE_ML/HITIT_Server/myenv/lib/python3.12/site-packages/waitress/server.py\", line 243, in __init__\n",
      "    self.bind_server_socket()\n",
      "  File \"/home/ubuntu/code/DE_ML/HITIT_Server/myenv/lib/python3.12/site-packages/waitress/server.py\", line 364, in bind_server_socket\n",
      "    self.bind(sockaddr)\n",
      "  File \"/home/ubuntu/code/DE_ML/HITIT_Server/myenv/lib/python3.12/site-packages/waitress/wasyncore.py\", line 395, in bind\n",
      "    return self.socket.bind(addr)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "OSError: [Errno 98] Address already in use\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from loaded_model\n",
      "입력 데이터: [[42454, 40, 32, 29.33, 291]]\n",
      "['안정적']\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "from flask import Flask, request, jsonify\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "flask_process = subprocess.Popen(['python3', 'app.py'])\n",
    "\n",
    "print(f\"Flask app is running with PID {flask_process.pid}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
